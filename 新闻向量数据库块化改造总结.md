# 新闻向量数据库块化改造总结

## 改造概述

本次改造将 `NewsVectorDB` 类的 `add_news` 方法从存储整篇新闻的向量改为将新闻切分成多个语义相关的"块"(Chunks)，并为每个块独立创建和存储向量。这种方法可以提高搜索的精确度和相关性。

## 主要改造内容

### 1. 依赖库更新

**文件**: `requirements.txt`
- 新增 `langchain` - 用于文本切分
- 新增 `tiktoken` - 用于token计算

### 2. 核心方法改造

#### 2.1 `add_news` 方法重构

**原始逻辑**:
- 将整篇新闻作为单个文档存储
- 每篇新闻对应一个向量
- 使用 `news_id` 作为文档ID

**新逻辑**:
- 使用 `LangChain` 的 `RecursiveCharacterTextSplitter` 将新闻切分成多个语义块
- 每个块独立存储，拥有自己的向量
- 块ID格式: `{news_id}_chunk_{序号}`
- 所有块共享原始新闻的元数据

**切分参数**:
```python
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=512,  # 每个块的目标大小（以token计）
    chunk_overlap=50, # 块之间的重叠大小
    separators=["\n\n", "\n", "。", "！", "？", "，", " "] # 优先使用的分隔符
)
```

#### 2.2 `semantic_search` 方法增强

**新增功能**:
- 支持块级搜索
- 自动合并同一新闻的多个块
- 返回合并后的新闻级结果

**合并逻辑**:
- 按 `news_id` 分组所有匹配的块
- 选择最相关的前3个块合并内容
- 使用最高分数作为新闻的整体分数
- 保留所有块的详细信息

#### 2.3 `_merge_chunks_by_news_id` 新方法

**功能**: 将同一新闻的多个块合并为一个搜索结果

**返回格式**:
```python
{
    'news_id': '原始新闻ID',
    'title': '新闻标题',
    'content': '合并后的内容（前3个最相关块）',
    'score': '最高匹配分数',
    'total_chunks': '总块数',
    'matched_chunks': '匹配块数',
    'chunk_details': [块详细信息列表],
    # ... 其他元数据
}
```

#### 2.4 `delete_news` 方法更新

**原始逻辑**: 删除单个文档ID

**新逻辑**:
- 查找指定 `news_id` 的所有块
- 批量删除所有相关块
- 记录删除的块数量

### 3. 元数据结构扩展

每个块的元数据包含:
```python
{
    "news_id": "原始新闻ID",
    "chunk_id": "块编号（从1开始）",
    "title": "新闻标题",
    "source": "新闻来源",
    "published_at": "发布时间",
    "category": "新闻分类",
    "sentiment_score": "情感分数",
    "importance_score": "重要性分数",
    "market_relevance": "市场相关性",
    "keywords": "关键词（JSON格式）",
    "language": "语言",
    "content_hash": "内容哈希（用于去重）"
}
```

## 兼容性处理

### 1. 向后兼容
- 保留原始 `add_news_original` 方法
- 在 `langchain` 未安装时自动回退到原始方法

### 2. 错误处理
- 文本切分失败时的优雅降级
- 依赖库缺失时的警告提示
- 详细的日志记录

## 性能优化

### 1. 批量操作
- 预计算整篇新闻的特征（关键词、市场相关性）
- 批量添加所有块到向量数据库
- 减少数据库交互次数

### 2. 搜索优化
- 块级精确匹配
- 智能内容合并
- 分数排序和结果限制

## 测试验证

### 测试脚本: `test_chunked_news_vector.py`

**测试内容**:
1. 新闻添加（块切分）功能
2. 语义搜索（块级搜索+合并）
3. 相似新闻查找
4. 市场相关新闻获取
5. 情感分析统计
6. 新闻删除（删除所有块）
7. 多新闻块处理

**测试结果**:
- ✅ 新闻成功切分并存储
- ✅ 搜索功能正常，能够合并同一新闻的多个块
- ✅ 删除功能正常，能够删除新闻的所有块
- ✅ 多新闻处理正常

## 改造优势

### 1. 搜索精度提升
- 块级匹配更精确
- 减少长文本中无关内容的干扰
- 提高相关性排序准确度

### 2. 存储效率优化
- 避免重复存储相似内容
- 支持大文档的有效处理
- 灵活的块大小控制

### 3. 功能扩展性
- 支持块级分析和统计
- 便于实现更复杂的搜索策略
- 为未来的RAG应用奠定基础

## 注意事项

### 1. 数据迁移
- 现有数据需要重新处理和切分
- 建议在测试环境充分验证后再迁移生产数据

### 2. 存储空间
- 块化存储可能增加总存储量（由于重叠和元数据）
- 需要监控数据库大小变化

### 3. 搜索行为变化
- 搜索结果的内容结构有所变化
- 调用方可能需要适配新的返回格式

## 后续优化建议

1. **动态块大小**: 根据新闻类型和长度动态调整块大小
2. **语义重叠**: 使用语义相似度而非字符重叠来优化块边界
3. **块权重**: 为不同位置的块分配不同权重（如标题块权重更高）
4. **缓存机制**: 为频繁搜索的查询添加结果缓存
5. **分数校准**: 优化相似度分数计算，提供更准确的相关性评估

---

**改造完成时间**: 2024年1月
**改造状态**: ✅ 完成并测试通过
**影响范围**: 新闻向量存储和搜索功能
**兼容性**: 向后兼容，支持渐进式迁移